{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import date\n",
    "from yahooquery import Ticker\n",
    "from utils_VaR import plot_scatter, plot_time_series_histogram, Security\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" visualization \"\"\"\n",
    "# T: time horizon (in days) for computing risk metrics\n",
    "# confidence level: 1-p for VaR, ES \n",
    "T = 120; p=5\n",
    "\n",
    "t0='1920-01-01'\n",
    "t1=date.today()\n",
    "\n",
    "sp500 = Security('^GSPC')\n",
    "sp500.set_df_historical_data(t0=t0, t1=t1)\n",
    "sp500.set_df_pct_change()\n",
    "sp500.set_df_risk(T=T, p=p, rolling_T=1) # to generate plot, set rolling T to 1. re-sampling is done in plot function for now\n",
    "df = sp500.get_df_risk()\n",
    "# read start and end date of past US recessions\n",
    "recession_periods = pd.read_csv('../data/recession_periods_NBER.csv') # use dates classified by NBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plot_scatter(df, t0='1960-1-1', t1='2010-6-30', T=1, recession_periods=recession_periods)\n",
    "# times series histogram\n",
    "plot_time_series_histogram(df, t0='2005-1-1', t1='2010-6-30', T=T, recession_periods=recession_periods, date_format='%B-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" collect analytic results for different assets \"\"\"\n",
    "# read recession periods\n",
    "recession_periods = pd.read_csv('../data/recession_periods_NBER.csv') # use dates classified by NBER\n",
    "recession_periods = recession_periods.astype({'Peak':'datetime64', 'Trough':'datetime64'})\n",
    "peaks = recession_periods['Peak'].values\n",
    "troughs = recession_periods['Trough'].values\n",
    "\n",
    "# set asset ticker and set time horizon and p level for computing VaR, ES\n",
    "securities = dict(sp500='^GSPC', agg='agg', gold='GC=F', oil='CL=F', GBPUSD='GBPUSD=X', tech_sec='XLK', energy_sec='XLE', russell_2k='^RUT')\n",
    "dict_Ts = dict(sp500=100, agg=50, gold=50, oil=50, GBPUSD=50, tech_sec=50, energy_sec=50, russell_2k=50)\n",
    "p=5\n",
    "# overall time horizon we want to consider\n",
    "t0 = '1920-1-1'\n",
    "t1 = date.today()\n",
    "\n",
    "# compute VaR, ES for all securities\n",
    "for i, key in enumerate(securities):\n",
    "    # length of time period for computing VaR, ES\n",
    "    T = dict_Ts[key]\n",
    "    rolling_T = T\n",
    "    # get historical data, compute VaR, ES\n",
    "    securities[key] = Security(securities[key]) # input ticker\n",
    "    securities[key].set_df_hist(t0=t0, t1=t1)\n",
    "    securities[key].set_df_pct_change()\n",
    "    securities[key].set_df_risk(T=dict_Ts[key], p=p, rolling_T=rolling_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" by recession \"\"\"\n",
    "columns=['asset', 'VaR', 'ES', 'VaR/ES', 'recession','sample size', 't-statistic', 'p-value']\n",
    "output = {}\n",
    "for i, key in enumerate(securities):\n",
    "    securities[key].label_recession_df(peaks=peaks, troughs=troughs, df='risk') # add recession (True/False) column\n",
    "    df = securities[key].get_df_risk()\n",
    "    \n",
    "    r = df[df['recession'] == True][['VaR', 'ES']] # all VaR and ES in recession periods\n",
    "    r_VaR_to_ESs = (r['VaR']/r['ES']).values # all VaR to ES ratios in recession periods\n",
    "    nr = df[df['recession'] == False][['VaR', 'ES']]\n",
    "    nr_VaR_to_ESs = (nr['VaR']/nr['ES']).values\n",
    "\n",
    "    ttest_res = ttest_ind(a=r_VaR_to_ESs, b=nr_VaR_to_ESs, equal_var=False)\n",
    "\n",
    "    output[i*2] = [key, np.mean(nr['VaR'].values), np.mean(nr['ES'].values), np.mean(nr_VaR_to_ESs), 'F', len(nr), '', '']\n",
    "    output[i*2+1] = [key, np.mean(r['VaR'].values), np.mean(r['ES'].values), np.mean(r_VaR_to_ESs), 'T', len(r), ttest_res[0], ttest_res[1]]\n",
    "\n",
    "df_tally = pd.DataFrame.from_dict(output, orient='index', columns=columns)\n",
    "df_tally.to_csv(f'tally_by_recession_[{t0} - {t1}).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" by market vol levels \"\"\"\n",
    "columns=['asset', 'VaR', 'ES', 'VaR/ES', 'volatility level','sample size', 't-statistic', 'p-value']\n",
    "output = {}\n",
    "for i, key in enumerate(securities):\n",
    "\n",
    "    securities[key].label_vol_level_df(T=dict_Ts[key]) # add vol level column\n",
    "\n",
    "    df = securities[key].get_df_risk()\n",
    "    \n",
    "    low = df[df['vol level'] == 'low'][['VaR', 'ES']] \n",
    "    low_VaR_to_ESs = (low['VaR']/low['ES']).values \n",
    "    high = df[df['vol level'] == 'high'][['VaR', 'ES']]\n",
    "    high_VaR_to_ESs = (high['VaR']/high['ES']).values\n",
    "\n",
    "    ttest_res = ttest_ind(a=low_VaR_to_ESs, b=high_VaR_to_ESs, equal_var=False)\n",
    "\n",
    "    output[i*2] = [key, np.mean(low['VaR'].values), np.mean(low['ES'].values), np.mean(low_VaR_to_ESs), 'Low', len(low), '', '']\n",
    "    output[i*2+1] = [key, np.mean(high['VaR'].values), np.mean(high['ES'].values), np.mean(high_VaR_to_ESs), 'High', len(high), ttest_res[0], ttest_res[1]]\n",
    "\n",
    "df_tally = pd.DataFrame.from_dict(output, orient='index', columns=columns)\n",
    "df_tally.to_csv(f'tally_by_vol_[{t0} - {t1}).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         asset       VaR        ES    VaR/ES volatility level  sample size  \\\n0        sp500  0.009551  0.013698  0.708926              Low          116   \n1        sp500  0.021823  0.031304  0.714947             High          116   \n2          agg  0.002542  0.003223  0.797191              Low           42   \n3          agg  0.004880  0.006913  0.747781             High           42   \n4         gold  0.010506  0.013981  0.758077              Low           62   \n5         gold  0.018412  0.025874  0.723223             High           62   \n6          oil  0.023141  0.030137  0.774727              Low           62   \n7          oil  0.043456  0.084452  0.753011             High           62   \n8       GBPUSD  0.006709  0.008522  0.793667              Low           43   \n9       GBPUSD  0.010873  0.014144  0.791720             High           43   \n10    tech_sec  0.012158  0.016523  0.741255              Low           54   \n11    tech_sec  0.030557  0.038202  0.802055             High           53   \n12  energy_sec  0.016402  0.020871  0.792030              Low           54   \n13  energy_sec  0.033855  0.041725  0.813878             High           53   \n14  russell_2k  0.010522  0.014143  0.749917              Low           83   \n15  russell_2k  0.025174  0.031783  0.796392             High           82   \n\n   t-statistic    p-value  \n0                          \n1    -0.385158   0.700479  \n2                          \n3      2.03401  0.0452974  \n4                          \n5      1.62246   0.107561  \n6                          \n7     0.978506   0.330005  \n8                          \n9    0.0861109   0.931587  \n10                         \n11    -2.61107  0.0105532  \n12                         \n13    -1.26521   0.208618  \n14                         \n15    -2.47767  0.0143582  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>VaR</th>\n      <th>ES</th>\n      <th>VaR/ES</th>\n      <th>volatility level</th>\n      <th>sample size</th>\n      <th>t-statistic</th>\n      <th>p-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sp500</td>\n      <td>0.009551</td>\n      <td>0.013698</td>\n      <td>0.708926</td>\n      <td>Low</td>\n      <td>116</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sp500</td>\n      <td>0.021823</td>\n      <td>0.031304</td>\n      <td>0.714947</td>\n      <td>High</td>\n      <td>116</td>\n      <td>-0.385158</td>\n      <td>0.700479</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>agg</td>\n      <td>0.002542</td>\n      <td>0.003223</td>\n      <td>0.797191</td>\n      <td>Low</td>\n      <td>42</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>agg</td>\n      <td>0.004880</td>\n      <td>0.006913</td>\n      <td>0.747781</td>\n      <td>High</td>\n      <td>42</td>\n      <td>2.03401</td>\n      <td>0.0452974</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gold</td>\n      <td>0.010506</td>\n      <td>0.013981</td>\n      <td>0.758077</td>\n      <td>Low</td>\n      <td>62</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>gold</td>\n      <td>0.018412</td>\n      <td>0.025874</td>\n      <td>0.723223</td>\n      <td>High</td>\n      <td>62</td>\n      <td>1.62246</td>\n      <td>0.107561</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>oil</td>\n      <td>0.023141</td>\n      <td>0.030137</td>\n      <td>0.774727</td>\n      <td>Low</td>\n      <td>62</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>oil</td>\n      <td>0.043456</td>\n      <td>0.084452</td>\n      <td>0.753011</td>\n      <td>High</td>\n      <td>62</td>\n      <td>0.978506</td>\n      <td>0.330005</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>GBPUSD</td>\n      <td>0.006709</td>\n      <td>0.008522</td>\n      <td>0.793667</td>\n      <td>Low</td>\n      <td>43</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GBPUSD</td>\n      <td>0.010873</td>\n      <td>0.014144</td>\n      <td>0.791720</td>\n      <td>High</td>\n      <td>43</td>\n      <td>0.0861109</td>\n      <td>0.931587</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>tech_sec</td>\n      <td>0.012158</td>\n      <td>0.016523</td>\n      <td>0.741255</td>\n      <td>Low</td>\n      <td>54</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>tech_sec</td>\n      <td>0.030557</td>\n      <td>0.038202</td>\n      <td>0.802055</td>\n      <td>High</td>\n      <td>53</td>\n      <td>-2.61107</td>\n      <td>0.0105532</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>energy_sec</td>\n      <td>0.016402</td>\n      <td>0.020871</td>\n      <td>0.792030</td>\n      <td>Low</td>\n      <td>54</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>energy_sec</td>\n      <td>0.033855</td>\n      <td>0.041725</td>\n      <td>0.813878</td>\n      <td>High</td>\n      <td>53</td>\n      <td>-1.26521</td>\n      <td>0.208618</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>russell_2k</td>\n      <td>0.010522</td>\n      <td>0.014143</td>\n      <td>0.749917</td>\n      <td>Low</td>\n      <td>83</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>russell_2k</td>\n      <td>0.025174</td>\n      <td>0.031783</td>\n      <td>0.796392</td>\n      <td>High</td>\n      <td>82</td>\n      <td>-2.47767</td>\n      <td>0.0143582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_tally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking non-overlapping time periods leaves us with fewer data points but it's pretty much in keeping with the assumption that\n",
    "two samples are independent when doing a t-test. However, we are left with small sample size (<30), so that the mean of a sample should follow a normal distribution may not hold. \n",
    "\n",
    "Taking over-lapping time periods significant violated t-test assumption due to strong auto-correlations. Currently, historical prices for all securities except sp500 are only available from 2000 to today, on Yahoo finance. For some securities, such as GBPUSD, more data seems to be available elsewhere, which can be 'manually' fed into the program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(df_tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda19daccaab569477d9dec399eeb89c3e8",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}